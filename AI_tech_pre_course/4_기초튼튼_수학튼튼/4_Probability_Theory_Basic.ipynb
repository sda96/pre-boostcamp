{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "received-florida",
   "metadata": {},
   "source": [
    "#### 딥러닝에서 확률론이 필요한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-diana",
   "metadata": {},
   "source": [
    "- 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두고 있습니다\n",
    "- 기계학습에서 사용되는 손실함수들의 작동원리는 데이터 공간을 통게쩍으로 해석해서 유도하게 됩니다.\n",
    "- 회귀 분석에서 손실함수로 사용되는 $L_2$ 노름은 예측 오차의 분산을 가장 최소화하는 방향으로 학습하도록 유도합니다\n",
    "- 분류 문제에서 사용되는 교차 엔트로피는 모델 예측의 불확실성을 최소화하는 방향으로 학습하도록 유도합니다\n",
    "- 분산 및 불확실성을 최소화하기 위해서는 측정하는 방법을 익혀야 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-roommate",
   "metadata": {},
   "source": [
    "#### 확률분포는 데이터의 초상화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-youth",
   "metadata": {},
   "source": [
    "- 데이터 공간을 $X \\times Y$라 표기하고 $D$ 는 데이터 공간에서 데이터를 추출하는 분포 입니다.\n",
    "- 해당 강의에서는 정답 레이블을 포함하고 있는 지도학습을 전제로 합니다\n",
    "- 데이터는 확률변수로 (x, y) ~ $D$ 라 표기\n",
    "- (x,y) $\\in$ $X \\times Y$는 데이터 공간 상의 관측가능한 데이터에 해당 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-maintenance",
   "metadata": {},
   "source": [
    "#### 확률변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-remains",
   "metadata": {},
   "source": [
    "- 확률변수 : 확률분포$D$에 따라 이산형(discrete)과 연속형(continuous) 확률변수로 구분하게 됩니다\n",
    "- 확률변수는 데이터 공간에 의해 결정된다 생각하지만 확률분포에 의해서 결정됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-slovenia",
   "metadata": {},
   "source": [
    "#### 이산확률변수 vs 연속확률변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-italic",
   "metadata": {},
   "source": [
    "- 이산형 확률변수 : 확률변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해서 모델링 합니다\n",
    "    - $P(X \\in A) = \\sum_{X \\in A}P(X=x)$\n",
    "- 연속형 확률변수 : 데이터 공간에 정의된 확률변수의 밀도위에서 적분을 통해 모델링 합니다\n",
    "    - $P(X \\in A) = \\int_{A}P(x)dx$\n",
    "    - 밀도함수 : $P(x) = \\lim_{h \\to 0}{\\frac{P(x-h \\le X \\le x+h)}{2h}}$\n",
    "    - 밀도는 누적확률분포의 변화율을 모델링하며 확률로 해석하면 안됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-arrest",
   "metadata": {},
   "source": [
    "#### 결합분포(joint distribution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "impaired-mitchell",
   "metadata": {},
   "source": [
    "- 결합분포 $P(x,y)$는 $D$를 모델링 합니다\n",
    "- 기존 그림의 형태는 연속확률분포로 보입니다\n",
    "- 빨간 선을 기준으로 데이터의 개수를 세는 경우 이산확률분포로 보입니다\n",
    "- 결합분포는 모델링 방법에 따라서 이산형인지, 연속형인지 달라집니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-fight",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/vu16WIk.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-european",
   "metadata": {},
   "source": [
    "#### 주변확률분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-pittsburgh",
   "metadata": {},
   "source": [
    "- $P(x)$는 Y의 값에 상관없이 빨간 칸 안에 있는 각 X에 따른 파란 색 점 데이터의 빈도를 세서 히스토그램으로 표현하였습니다\n",
    "- $P(x)$는 입력 x에 대한 주변확률분포로 y 에 대한 정보를 주진 않습니다\n",
    "    - 이산형 주변확률분포 : $P(x) = \\sum_{y}P(x,y)$\n",
    "    - 연속형 주변확률분포 : $P(x) = \\int_{y}P(x,y)dy$\n",
    "- 주변확률분포 $P(x)$는 결합분포 $P(x,y)$에서 y를 모두 더하거나 적분을 하여 유도 가능 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-generator",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/rOWojRl.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-norfolk",
   "metadata": {},
   "source": [
    "#### 조건부 확률분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-discretion",
   "metadata": {},
   "source": [
    "- y에 대한 조건부 확률분포인 $P(x|y)$는 특정조건 y = 1 이 주어진 환경에서 x에 대한 확률분포를 모델링합니다\n",
    "- 조건부 확률분포는 입력 x 와 출력 y 사이의 관계를 모델링합니다\n",
    "- 조건부 확률분포는 주어진 조건에서 데이터의 확률분포를 보여줍니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "likely-multiple",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/cSh6PQS.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-frontier",
   "metadata": {},
   "source": [
    "#### 조건부 확률과 기계학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-pitch",
   "metadata": {},
   "source": [
    "- 조건부 확률 $P(y|x)$는 입력변수 x 에 대해 정답이 y 일 확률을 의미합니다\n",
    "- 연속확률분포의 경우 확률이 아니고 밀도로 해석해야 합니다\n",
    "- 로지스틱 회귀에서 사용했던 선형모델과 소프트맥수 함수의 결합은 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용됩니다\n",
    "- 분류 문제에서 소프트맥스($W\\phi(x)+b$)는 데이터 x 로부터 추출된 특징패턴 $\\phi(x)$ 과 가중치 행렬 $W$을 통해 조건부 확률 $P(y|\\phi(x))$을 계산합니다\n",
    "- 회귀 문제의 경우 보통 연속확률변수를 다루기에 조건부 기대값 $E(y|x)$를 추정합니다\n",
    "    - 조건부 기대값 : $E_{y \\sim P(y|x)}[y|x] = \\int_{y}yP(y|x)dy$\n",
    "    - 조건부 기대값은 $E||y-f(x)||_2$을 최소화하는 함수 $f(x)$와 일치합니다\n",
    "    - 관찰되는 데이터가 로버스트하게 예측하는 경우 조건부 기대값보다 중앙값을 사용하여 추정하기도 합니다\n",
    "    - 문제를 해결하는 목적에 따라서 추정하는 추정량(estimator)가 달라 질 수 있습니다\n",
    "- 딥러닝은 다층신경망을 사용하여 데이터로부터 특징 패턴 $\\phi$을 추출합니다\n",
    "- 특징패턴을 학습하기 위해 어떤 손실함수를 사용할지는 기계학습 문제와 모델에 의해 결정됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-nature",
   "metadata": {},
   "source": [
    "#### 기대값이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-yeast",
   "metadata": {},
   "source": [
    "- 확률분포가 주어지면 데이터를 분석하는데 사용 가능한 여러 종류의 통계적 범함수(statistical functional)를 계산할 수 있습니다\n",
    "- 기대값(expetation)은 데이터를 대표하는 통계량이면서 동시에 확률분포를 통해 다른 통계적 범함수를 계산하는데 사용됩니다\n",
    "    - 연속형 확률변수의 기대값 : $E_{x \\sim P(x)}(f(x)) = \\int f(x)P(x)dx$\n",
    "    - 이산형 확률변수의 기대값 : $E_{x \\sim P(x)}(f(x)) = \\sum f(x)P(x)dx$\n",
    "- 기대값을 사용하여 분산, 첨도, 공분산 등 여러 통계량을 계산할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-conjunction",
   "metadata": {},
   "source": [
    "#### 몬테카를로 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-marking",
   "metadata": {},
   "source": [
    "- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분 입니다\n",
    "- 확률분포를 모를 떄, 데이터를 이용하여 기대값을 계싼하려면 몬테카를로 샘플링 방법을 사용해야 합니다\n",
    "- 몬테카를로 샘플링은 이산형이든 연속형이든 상관없이 성립합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-number",
   "metadata": {},
   "source": [
    "몬테카를로 샘플링: $E_{x \\sim P(x)}[f(x)] \\approx \\frac{1}{N} \\sum{f(x^{(i)}), x^{(i)} \\sim i.i.d P(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-fellow",
   "metadata": {},
   "source": [
    "- 각 데이터는 독립 추출 이어야 합니다\n",
    "- 독립추출이 보장된다면 대수의 법칙에의해서 수렴성을 보장합니다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
